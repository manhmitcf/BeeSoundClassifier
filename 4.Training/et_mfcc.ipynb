{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“‚ Batch 0\n",
      "Training Extra Trees Classifier\n",
      "MFCC: 13\n",
      "[[1026   64    5]\n",
      " [ 125  379  188]\n",
      " [   2   30  941]]\n",
      "MFCC: 20\n",
      "[[1033   59    3]\n",
      " [ 120  379  193]\n",
      " [   0   30  943]]\n",
      "MFCC: 40\n",
      "[[1038   55    2]\n",
      " [ 123  374  195]\n",
      " [   0   27  946]]\n",
      "MFCC: 80\n",
      "[[1052   43    0]\n",
      " [ 127  369  196]\n",
      " [   0   19  954]]\n",
      "\n",
      "ðŸ“Œ Káº¿t quáº£ Batch 0 - Extra Trees:\n",
      "   numofMFCC  n_fft  Hop_length  test_accuracy  macro_f1      time\n",
      "0         13   1024         256       0.850000  0.818889  1.390945\n",
      "1         20   1024         256       0.853261  0.821827  1.773349\n",
      "2         40   1024         256       0.854348  0.821974  2.137008\n",
      "3         80   1024         256       0.860507  0.827046  2.057748\n",
      "\n",
      "ðŸ“‚ Batch 1\n",
      "Training Extra Trees Classifier\n",
      "MFCC: 13\n",
      "[[1029   61    5]\n",
      " [ 121  379  192]\n",
      " [   2   35  936]]\n",
      "MFCC: 20\n",
      "[[1034   59    2]\n",
      " [ 122  382  188]\n",
      " [   0   27  946]]\n",
      "MFCC: 40\n",
      "[[1042   51    2]\n",
      " [ 117  380  195]\n",
      " [   0   26  947]]\n",
      "MFCC: 80\n",
      "[[1049   45    1]\n",
      " [ 128  371  193]\n",
      " [   1   17  955]]\n",
      "\n",
      "ðŸ“Œ Káº¿t quáº£ Batch 1 - Extra Trees:\n",
      "   numofMFCC  n_fft  Hop_length  test_accuracy  macro_f1      time\n",
      "0         13   1024         512       0.849275  0.818102  1.373982\n",
      "1         20   1024         512       0.855797  0.824810  1.531171\n",
      "2         40   1024         512       0.858333  0.826895  1.779301\n",
      "3         80   1024         512       0.860507  0.827553  2.251752\n",
      "\n",
      "ðŸ“‚ Batch 2\n",
      "Training Extra Trees Classifier\n",
      "MFCC: 13\n",
      "[[1023   66    6]\n",
      " [ 121  378  193]\n",
      " [   1   33  939]]\n",
      "MFCC: 20\n",
      "[[1032   61    2]\n",
      " [ 128  376  188]\n",
      " [   0   24  949]]\n",
      "MFCC: 40\n",
      "[[1043   51    1]\n",
      " [ 126  369  197]\n",
      " [   0   22  951]]\n",
      "MFCC: 80\n",
      "[[1052   43    0]\n",
      " [ 131  360  201]\n",
      " [   0   17  956]]\n",
      "\n",
      "ðŸ“Œ Káº¿t quáº£ Batch 2 - Extra Trees:\n",
      "   numofMFCC  n_fft  Hop_length  test_accuracy  macro_f1      time\n",
      "0         13   2048         512       0.847826  0.816575  1.000438\n",
      "1         20   2048         512       0.853986  0.822062  1.487362\n",
      "2         40   2048         512       0.856159  0.822832  1.888296\n",
      "3         80   2048         512       0.857971  0.822917  2.292051\n",
      "\n",
      "ðŸ“‚ Batch 3\n",
      "Training Extra Trees Classifier\n",
      "MFCC: 13\n",
      "[[1028   63    4]\n",
      " [ 126  374  192]\n",
      " [   2   28  943]]\n",
      "MFCC: 20\n",
      "[[1030   64    1]\n",
      " [ 129  367  196]\n",
      " [   0   29  944]]\n",
      "MFCC: 40\n",
      "[[1045   49    1]\n",
      " [ 130  365  197]\n",
      " [   0   26  947]]\n",
      "MFCC: 80\n",
      "[[1046   48    1]\n",
      " [ 129  364  199]\n",
      " [   0   19  954]]\n",
      "\n",
      "ðŸ“Œ Káº¿t quáº£ Batch 3 - Extra Trees:\n",
      "   numofMFCC  n_fft  Hop_length  test_accuracy  macro_f1      time\n",
      "0         13   2048        1024       0.849638  0.817621  1.003580\n",
      "1         20   2048        1024       0.848188  0.814726  1.368734\n",
      "2         40   2048        1024       0.853986  0.819940  2.068290\n",
      "3         80   2048        1024       0.856522  0.822296  2.233247\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n",
    "from sklearn.ensemble import ExtraTreesClassifier  # Import Extra Trees\n",
    "\n",
    "def load_data_by_batch(csv_path, batch_id):\n",
    "    df = pd.read_csv(csv_path)\n",
    "    df[\"Bá»™\"] = df[\"Bá»™\"].astype(int)\n",
    "    batch_df = df[df[\"Bá»™\"] == batch_id]\n",
    "    \n",
    "    n_fft = batch_df[\"n_fft\"].values[0]\n",
    "    hop_length = batch_df[\"hop_length\"].values[0]\n",
    "    \n",
    "    train_row = batch_df[batch_df[\"Táº­p\"] == \"train\"]\n",
    "    test_row = batch_df[batch_df[\"Táº­p\"] == \"test\"]\n",
    "    \n",
    "    X_train = np.load(train_row[\"X_file_path\"].values[0])\n",
    "    y_train = np.load(train_row[\"y_file_path\"].values[0])\n",
    "    X_test = np.load(test_row[\"X_file_path\"].values[0])\n",
    "    y_test = np.load(test_row[\"y_file_path\"].values[0])\n",
    "    \n",
    "    return X_train, y_train, X_test, y_test, n_fft, hop_length\n",
    "\n",
    "def run_et_experiment(X_train, y_train, X_test, y_test, n_fft, hop_length, mfcc_steps):\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train.reshape(X_train.shape[0], -1))\n",
    "    X_test_scaled = scaler.transform(X_test.reshape(X_test.shape[0], -1))\n",
    "    \n",
    "    et = ExtraTreesClassifier(n_estimators=100, random_state=42)\n",
    "    \n",
    "    results = []\n",
    "    for i in mfcc_steps:\n",
    "        X_train_subset = X_train_scaled[:, :i]\n",
    "        X_test_subset = X_test_scaled[:, :i]\n",
    "        \n",
    "        start_time = time.time()\n",
    "        et.fit(X_train_subset, y_train)\n",
    "        y_pred = et.predict(X_test_subset)\n",
    "        test_accuracy = accuracy_score(y_test, y_pred)\n",
    "        macro_f1 = f1_score(y_test, y_pred, average='macro')\n",
    "        confusion = confusion_matrix(y_test, y_pred)\n",
    "        \n",
    "        print(f\"MFCC: {i}\")\n",
    "        print(confusion)\n",
    "        \n",
    "        elapsed_time = time.time() - start_time\n",
    "        results.append({\n",
    "            'numofMFCC': i,\n",
    "            'n_fft': n_fft,\n",
    "            'Hop_length': hop_length,\n",
    "            'test_accuracy': test_accuracy,\n",
    "            'macro_f1': macro_f1,\n",
    "            'time': elapsed_time\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "# Cháº¡y thá»­ nghiá»‡m vá»›i Extra Trees\n",
    "mfcc_steps = [13, 20, 40, 80]\n",
    "csv_path = r\"C:\\Users\\manhm\\Desktop\\BeeSoundClassifier\\data\\extracted_features\\mfcc\\mfcc_extraction_log.csv\"\n",
    "\n",
    "for i in range(0, 4):\n",
    "    batch_id = i\n",
    "    data = load_data_by_batch(csv_path, batch_id)\n",
    "    \n",
    "    if data is None:\n",
    "        continue\n",
    "    \n",
    "    print(f\"\\nðŸ“‚ Batch {batch_id}\")\n",
    "    print(\"Training Extra Trees Classifier\")\n",
    "    X_train, y_train, X_test, y_test, n_fft, hop_length = data\n",
    "    df_et = run_et_experiment(X_train, y_train, X_test, y_test, n_fft, hop_length, mfcc_steps)\n",
    "    print(f\"\\nðŸ“Œ Káº¿t quáº£ Batch {batch_id} - Extra Trees:\")\n",
    "    print(df_et)\n",
    "    df_et.to_csv(f\"et_results_batch_{batch_id}.csv\", index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
